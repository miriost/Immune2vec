{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Cross-validation: some gotchas\n",
    "===============================\n",
    "\n",
    "Cross-validation is the ubiquitous test of a machine learning model. Yet\n",
    "many things can go wrong.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uncertainty of measured accuracy\n",
    "------------------------------------\n",
    "\n",
    "The first thing to have in mind is that the results of a\n",
    "cross-validation are noisy estimate of the real prediction accuracy\n",
    "\n",
    "Let us create a simple artificial data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, discriminant_analysis\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "data, target = datasets.make_blobs(centers=[(0, 0), (0, 1)])\n",
    "classifier = discriminant_analysis.LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One cross-validation gives spread out measures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(cross_val_score(classifier, data, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we try different random shuffles of the data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import utils\n",
    "for _ in range(10):\n",
    "    data, target = utils.shuffle(data, target)\n",
    "    print(cross_val_score(classifier, data, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should not be surprising: if the lassification rate is p, the\n",
    "observed distribution of correct classifications on a set of size\n",
    "follows a binomial distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "n = len(data)\n",
    "distrib = stats.binom(n=n, p=.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot it:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.plot(np.linspace(0, 1, n), distrib.pmf(np.arange(0, n)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is wide, because there are not that many samples to mesure the error\n",
    "upon: iris is a small dataset\n",
    "\n",
    "We can look at the interval in which 95% of the observed accuracy lies\n",
    "for different sample sizes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [100, 1000, 10000, 100000]:\n",
    "    distrib = stats.binom(n, .7)\n",
    "    interval = (distrib.isf(.025) - distrib.isf(.975)) / n\n",
    "    print(\"Size: {0: 7}  | interval: {1}%\".format(n, 100 * interval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At 100 000 samples, 5% of the observed classification accuracy still\n",
    "fall more than .5% away of the true rate\n",
    "\n",
    "**Keep in mind that cross-val is a noisy measure**\n",
    "\n",
    "Importantly, the variance across folds is not a good measure of this\n",
    "error, as the different data folds are not independent. For instance,\n",
    "doing many random splits will can reduce the variance arbitrarily, but\n",
    "does not provide actually new data points\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confounding effects and non independence\n",
    "-----------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measuring baselines and chance\n",
    "-------------------------------\n",
    "\n",
    "Because of class imbalances, or confounding effects, it is easy to get\n",
    "it wrong it terms of what constitutes chances. There are two approaches\n",
    "to measure peformances of baselines or chance:\n",
    "\n",
    "**DummyClassifier** The dummy classifier:\n",
    ":class:`sklearn.dummy.DummyClassifier`, with different strategies to\n",
    "provide simple baselines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dummy = DummyClassifier(strategy=\"stratified\")\n",
    "print(cross_val_score(dummy, data, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chance level** To measure actual chance, the most robust approach is\n",
    "to use permutations:\n",
    ":func:`sklearn.model_selection.permutation_test_score`, which is used\n",
    "as cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import permutation_test_score\n",
    "score, permuted_scores, p_value = permutation_test_score(classifier, data, target)\n",
    "print(\"Classifier score: {0},\\np value: {1}\\nPermutation scores {2}\"\n",
    "        .format(score, p_value, permuted_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
